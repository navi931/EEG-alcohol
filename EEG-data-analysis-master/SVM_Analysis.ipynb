{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center><font size=5>EEG Data Analysis and Machine Learning(SVM)</font></center>**\n",
    "***<center>Alcoholic vs Control Groups</center>***\n",
    "***\n",
    "**Autor**: Iván García Alvarez\n",
    "\n",
    "**Fecha**: 23 Marzo del 2019\n",
    "\n",
    "**[GitHub Repository](https://github.com/ruslan-kl/EEG-data-analysis)**\n",
    "\n",
    "#### Table of Contents\n",
    "- <a href='#intro'>1. Project Overview</a> \n",
    "- <a href='#env'>2. Setting up the Environment</a>\n",
    "- <a href='#import'>2.1. Data Import</a>\n",
    "- <a href='#Preprocessing'>5. Preprocessing</a>\n",
    "- <a href='#Training'>5. Training</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='intro'>1.Project Overview</a>\n",
    "\n",
    "Este proyecto ha sido publicado en Kaggle [EEG-Alcohol](https://www.kaggle.com/ruslankl/eeg-data-analysis) como un reto para implementar Machine Learning, así que hemos tomado el reto y en este proyecto implementaremos Support Vector Machines.Al igual que el estudio de kaggle he escogido el [EEG-Alcohol](https://www.kaggle.com/nnair25/Alcoholics) dataset, el cual [EEG (Electroencephalography)](https://en.wikipedia.org/wiki/Electroencephalography) que son los datos de dos grupos - Alcoholic and Control Group. \n",
    "![](https://i.imgur.com/ZrmxJRu.jpg)\n",
    "La cantidad de sujetos en cada grupo es 8. Los 64 electrodos se colocaron en el cuero cabelludo del sujeto para medir la actividad eléctrica del cerebro. Los valores de respuesta se muestrearon a 256 Hz (época de 3.9 ms) durante 1 segundo. Cada sujeto fue expuesto a un solo estímulo (S1) o a dos estímulos (S1 y S2) que eran imágenes de objetos elegidos de entre [1980 Snodgrass and Vanderwart picture set](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.1979&rep=rep1&type=pdf). Cuando se mostraron dos estímulos, se presentaron en una condición emparejada donde S1 era idéntico a S2 o en una condición no emparejada donde S1 difería de S2.\n",
    "\n",
    "El propósito del algoritmo será detectar diferencias entre los valores de respuesta para diferentes estímulos entre el control y el grupo alcohólico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='env'>2. Setting up the Environment</a>\n",
    "## <a id='import'>2.1. Data Import</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='Preprocessing'>Preprocessing</a>\n",
    "Lo primero que haremos será hacer el preprcesamiento de los datos, tomaremos en cuenta las siguientes recomendaciones para esto:\n",
    "* No nos interesa un \"id\" del sujeto, pues puede ocasionar un overfitting\n",
    "\n",
    "* Nos interesa mucho cuales sensores son los sensores importantes, para esto tomaremos las conclusiones dadas por el estudio previo que son 'FPZ', 'FP2', 'AF3', 'AFZ', 'AF4', 'F5', 'F3', 'F1', 'FZ', 'FC5', 'FC3', 'FCZ', 'T7', 'CZ', 'C4', 'C6','TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP8', 'P5', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO4', 'O1'\n",
    "\n",
    "* Analizando los datos nos dimos cuenta que la posicion del sensor y el canal, es lo mismo entonces por motivos de procesamiento hemos decidir eliminar el campo chanel.\n",
    "\n",
    "* Para un mejor rendimiento del algoritmo se ha decidido dejar todo en valores númericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def filter_columns():\n",
    "    path = '../Train'\n",
    "    columns = [2,3,4,5,6,7]\n",
    "    set_headers = True\n",
    "    fw = open('filtered_train_data.csv', 'w')\n",
    "    fw2 = open('filtered_test_data.csv', 'w')\n",
    "\n",
    "    os.chdir(path)\n",
    "    for file in tqdm(os.listdir('./')):\n",
    "        f = open(file)\n",
    "        flines = f.readlines()\n",
    "        flen = len(flines)\n",
    "        if flen > 1:\n",
    "            if set_headers:\n",
    "                hsplit = flines[0].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    temp_line.append(hsplit[col])\n",
    "                \n",
    "                fw.write(\",\".join(temp_line))\n",
    "                set_headers = False\n",
    "\n",
    "            for i in range(1, flen):\n",
    "                xsplit = flines[i].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    try:\n",
    "                        temp_line.append(xsplit[col])\n",
    "                    except:\n",
    "                        print(file)\n",
    "                \n",
    "                fw.write(\",\".join(temp_line) + '\\n')\n",
    "    set_headers = True            \n",
    "    print(\"listo train\")\n",
    "    path = '../Test'\n",
    "    os.chdir(path)\n",
    "    for file in tqdm(os.listdir('./')):\n",
    "        f = open(file)\n",
    "        flines = f.readlines()\n",
    "        flen = len(flines)\n",
    "        if flen > 1:\n",
    "            if set_headers:\n",
    "                hsplit = flines[0].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    temp_line.append(hsplit[col])\n",
    "                \n",
    "                fw2.write(\",\".join(temp_line))\n",
    "                set_headers = False\n",
    "\n",
    "            for i in range(1, flen):\n",
    "                xsplit = flines[i].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    try:\n",
    "                        temp_line.append(xsplit[col])\n",
    "                    except:\n",
    "                        print(file)\n",
    "                \n",
    "                fw2.write(\",\".join(temp_line) + '\\n')\n",
    "\n",
    "        f.close()\n",
    "    fw.close()\n",
    "    fw2.close()\n",
    "    os.chdir('../EEG-data-analysis-master')\n",
    "\n",
    "def change_sensors():\n",
    "    sensors_dict = {\n",
    "        'AF1': 'AF3',\n",
    "        'AF2': 'AF4',\n",
    "        'PO1': 'PO3',\n",
    "        'PO2': 'PO4'\n",
    "    }\n",
    "    f = open('filtered_train_data.csv')\n",
    "    fw = open('changed_train_sensor_data.csv', 'w')\n",
    "    f2 = open('filtered_test_data.csv')\n",
    "    fw2 = open('changed_test_sensor_data.csv', 'w')\n",
    "\n",
    "    flines = f.readlines()\n",
    "    fw.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 1:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in sensors_dict:\n",
    "                xsplit[0] = sensors_dict.get(xsplit[0])\n",
    "\n",
    "            fw.write(\",\".join(xsplit))\n",
    "            \n",
    "    flines = f2.readlines()\n",
    "    fw2.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 1:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in sensors_dict:\n",
    "                xsplit[0] = sensors_dict.get(xsplit[0])\n",
    "\n",
    "            fw2.write(\",\".join(xsplit))\n",
    "    \n",
    "\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    f2.close()\n",
    "    fw2.close()\n",
    "\n",
    "def filter_sensor():\n",
    "    good_sensors = ['FPZ', 'FP2', 'AF3', 'AFZ', 'AF4', 'F5', 'F3', 'F1', 'FZ', 'FC5', 'FC3', 'FCZ', 'T7', 'CZ', 'C4', 'C6', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP8', 'P5', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO4', 'O1']\n",
    "\n",
    "    f = open('changed_train_sensor_data.csv')\n",
    "    fw = open('changed_train_sensor_data_cool.csv', 'w')\n",
    "    f2 = open('changed_test_sensor_data.csv')\n",
    "    fw2 = open('changed_test_sensor_data_cool.csv', 'w')\n",
    "\n",
    "    flines = f.readlines()\n",
    "    fw.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in good_sensors:\n",
    "                xsplit[0] = str(good_sensors.index(xsplit[0]))\n",
    "                fw.write(\",\".join(xsplit))\n",
    "        \n",
    "    flines = f2.readlines()\n",
    "    fw2.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in good_sensors:\n",
    "                xsplit[0] = str(good_sensors.index(xsplit[0]))\n",
    "                fw2.write(\",\".join(xsplit))\n",
    "\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    f2.close()\n",
    "    fw2.close()\n",
    "\n",
    "def juntar_test_data():\n",
    "    f_new = open('data.csv', 'w')\n",
    "    f1 = open('test_data.csv')\n",
    "    f2 = open('train_data.csv')\n",
    "    \n",
    "    flines = f1.readlines()\n",
    "    \n",
    "    f_new.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            f_new.write(\",\".join(xsplit))\n",
    "                \n",
    "    flines = f2.readlines()\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            f_new.write(\",\".join(xsplit))\n",
    "\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f_new.close()\n",
    "\n",
    "def limpiar_s():\n",
    "    f1_new = open('train_data.csv','w')\n",
    "    f2_new = open('test_data.csv','w')\n",
    "    f1 = open('changed_train_sensor_data_cool.csv')\n",
    "    f2 = open('changed_test_sensor_data_cool.csv')\n",
    "\n",
    "    flines = f1.readlines()\n",
    "    \n",
    "    f1_new.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if(xsplit[4] == 'S1 obj'):\n",
    "                xsplit[4] = '1'\n",
    "            elif('S2 nomatch' in xsplit[4]):\n",
    "                xsplit[4] = '2'\n",
    "            elif(xsplit[4]== 'S2 match'):\n",
    "                xsplit[4] = '3'\n",
    "                \n",
    "            if(xsplit[0] == 'S1 obj'):\n",
    "                xsplit[0] = '1'\n",
    "            elif('S2 nomatch' in xsplit[4]):\n",
    "                xsplit[0] = '2'\n",
    "            elif(xsplit[0]== 'S2 match'):\n",
    "                xsplit[0] = '3'\n",
    "            if(xsplit[5] < '64'):\n",
    "                f2_new.write(\",\".join(xsplit))\n",
    "\n",
    "                \n",
    "    flines = f2.readlines()\n",
    "    f2_new.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if(xsplit[4] == 'S1 obj'):\n",
    "                xsplit[4] = '1'\n",
    "            elif('S2 nomatch' in xsplit[4]):\n",
    "                xsplit[4] = '2'\n",
    "            elif(xsplit[4]== 'S2 match'):\n",
    "                xsplit[4] = '3'\n",
    "            f1_new.write(\",\".join(xsplit))\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f1_new.close()\n",
    "    f2_new.close()\n",
    "                \n",
    "\n",
    "print('Empezando')\n",
    "print('filtrando columnas')\n",
    "#filter_columns()\n",
    "print('cambiando los nombres de los sensores')\n",
    "#change_sensors()\n",
    "print('filtrando sensores')\n",
    "#filter_sensor()\n",
    "print('limpiando s')\n",
    "#limpiar_s()\n",
    "print('juntando test and train')\n",
    "#juntar_test_data()\n",
    "print('terminado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enseguida procederemos a visualizar los datos para aplicar los filtros necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_position</th>\n",
       "      <th>sample_num</th>\n",
       "      <th>sensor_value</th>\n",
       "      <th>subject_identifier</th>\n",
       "      <th>matching_condition</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.276</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.717</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.670</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9.623</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9.623</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.647</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5.229</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.322</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.096</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_position  sample_num  sensor_value subject_identifier  \\\n",
       "0                1           0         0.834                  a   \n",
       "1                1           1         3.276                  a   \n",
       "2                1           2         5.717                  a   \n",
       "3                1           3         7.670                  a   \n",
       "4                1           4         9.623                  a   \n",
       "5                1           5         9.623                  a   \n",
       "6                1           6         8.647                  a   \n",
       "7                1           7         5.229                  a   \n",
       "8                1           8         1.322                  a   \n",
       "9                1           9        -2.096                  a   \n",
       "\n",
       "   matching_condition channel  \n",
       "0                   1       1  \n",
       "1                   1       1  \n",
       "2                   1       1  \n",
       "3                   1       1  \n",
       "4                   1       1  \n",
       "5                   1       1  \n",
       "6                   1       1  \n",
       "7                   1       1  \n",
       "8                   1       1  \n",
       "9                   1       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\",encoding='latin-1')\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enseguida lo que haremos sera clasificar los alcoholicos 'a' como 1 y grupo de control como 0 (campo a clasificar)\n",
    "además que solo usaremos los campos \"sensor_position\",\"sample_num\",\"sensor_value\",\"matching_condition\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"subject_identifier\"]=data[\"subject_identifier\"].map({'a':1,'c':0})\n",
    "temporal = [[data[\"sensor_position\"]],[data[\"sample_num\"]],[data[\"sensor_value\"]],[data[\"matching_condition\"]]]\n",
    "train = np.array(temporal)\n",
    "y = np.array([data['subject_identifier']])\n",
    "\n",
    "train = train.reshape(6621824,4)\n",
    "y = y.reshape(6621824,1)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train , y, test_size=0.00001, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='Training'>Training</a>\n",
    "Teniendo los datasets de train y de prueba procederemos a entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "svc.fit(X_test, y_test)\n",
    "#score_test = svc.score(X_test, y_test)\n",
    "#recall_test = metrics.recall_score(y_test, svc.predict(X_test))\n",
    "#precision_test = metrics.precision_score(y_test, svc.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
