{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Environment\n",
    " Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "Lo primero que haremos será hacer el preprcesamiento de los datos, tomaremos en cuenta las siguientes recomendaciones para esto:\n",
    "* No nos interesa un \"id\" del sujeto, pues puede ocasionar un overfitting\n",
    "\n",
    "* Nos interesa mucho cuales sensores son los sensores importantes, para esto tomaremos las conclusiones dadas por el estudio previo que son 'FPZ', 'FP2', 'AF3', 'AFZ', 'AF4', 'F5', 'F3', 'F1', 'FZ', 'FC5', 'FC3', 'FCZ', 'T7', 'CZ', 'C4', 'C6','TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP8', 'P5', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO4', 'O1'\n",
    "\n",
    "* Analizando los datos nos dimos cuenta que la posicion del sensor y el canal, es lo mismo entonces por motivos de procesamiento hemos decidir eliminar el campo chanel.\n",
    "\n",
    "* Para un mejor rendimiento del algoritmo se ha decidido dejar todo en valores númericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empezando\n",
      "filtrando columnas\n",
      "cambiando los nombres de los sensores\n",
      "filtrando sensores\n",
      "limpiando s\n",
      "juntando test and train\n",
      "terminado\n"
     ]
    }
   ],
   "source": [
    "def filter_columns():\n",
    "    path = '../Train'\n",
    "    columns = [2,3,4,5,6,7]\n",
    "    set_headers = True\n",
    "    fw = open('filtered_train_data.csv', 'w')\n",
    "    fw2 = open('filtered_test_data.csv', 'w')\n",
    "\n",
    "    os.chdir(path)\n",
    "    for file in tqdm(os.listdir('./')):\n",
    "        f = open(file)\n",
    "        flines = f.readlines()\n",
    "        flen = len(flines)\n",
    "        if flen > 1:\n",
    "            if set_headers:\n",
    "                hsplit = flines[0].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    temp_line.append(hsplit[col])\n",
    "                \n",
    "                fw.write(\",\".join(temp_line))\n",
    "                set_headers = False\n",
    "\n",
    "            for i in range(1, flen):\n",
    "                xsplit = flines[i].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    try:\n",
    "                        temp_line.append(xsplit[col])\n",
    "                    except:\n",
    "                        print(file)\n",
    "                \n",
    "                fw.write(\",\".join(temp_line) + '\\n')\n",
    "    set_headers = True            \n",
    "    print(\"listo train\")\n",
    "    path = '../Test'\n",
    "    os.chdir(path)\n",
    "    for file in tqdm(os.listdir('./')):\n",
    "        f = open(file)\n",
    "        flines = f.readlines()\n",
    "        flen = len(flines)\n",
    "        if flen > 1:\n",
    "            if set_headers:\n",
    "                hsplit = flines[0].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    temp_line.append(hsplit[col])\n",
    "                \n",
    "                fw2.write(\",\".join(temp_line))\n",
    "                set_headers = False\n",
    "\n",
    "            for i in range(1, flen):\n",
    "                xsplit = flines[i].split(',')\n",
    "                temp_line = []\n",
    "                for col in columns:\n",
    "                    try:\n",
    "                        temp_line.append(xsplit[col])\n",
    "                    except:\n",
    "                        print(file)\n",
    "                \n",
    "                fw2.write(\",\".join(temp_line) + '\\n')\n",
    "\n",
    "        f.close()\n",
    "    fw.close()\n",
    "    fw2.close()\n",
    "    os.chdir('../EEG-data-analysis-master')\n",
    "\n",
    "def change_sensors():\n",
    "    sensors_dict = {\n",
    "        'AF1': 'AF3',\n",
    "        'AF2': 'AF4',\n",
    "        'PO1': 'PO3',\n",
    "        'PO2': 'PO4'\n",
    "    }\n",
    "    f = open('filtered_train_data.csv')\n",
    "    fw = open('changed_train_sensor_data.csv', 'w')\n",
    "    f2 = open('filtered_test_data.csv')\n",
    "    fw2 = open('changed_test_sensor_data.csv', 'w')\n",
    "\n",
    "    flines = f.readlines()\n",
    "    fw.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 1:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in sensors_dict:\n",
    "                xsplit[0] = sensors_dict.get(xsplit[0])\n",
    "\n",
    "            fw.write(\",\".join(xsplit))\n",
    "            \n",
    "    flines = f2.readlines()\n",
    "    fw2.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 1:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in sensors_dict:\n",
    "                xsplit[0] = sensors_dict.get(xsplit[0])\n",
    "\n",
    "            fw2.write(\",\".join(xsplit))\n",
    "    \n",
    "\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    f2.close()\n",
    "    fw2.close()\n",
    "\n",
    "def filter_sensor():\n",
    "    good_sensors = ['FPZ', 'FP2', 'AF3', 'AFZ', 'AF4', 'F5', 'F3', 'F1', 'FZ', 'FC5', 'FC3', 'FCZ', 'T7', 'CZ', 'C4', 'C6', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP8', 'P5', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO4', 'O1']\n",
    "\n",
    "    f = open('changed_train_sensor_data.csv')\n",
    "    fw = open('changed_train_sensor_data_cool.csv', 'w')\n",
    "    f2 = open('changed_test_sensor_data.csv')\n",
    "    fw2 = open('changed_test_sensor_data_cool.csv', 'w')\n",
    "\n",
    "    flines = f.readlines()\n",
    "    fw.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in good_sensors:\n",
    "                xsplit[0] = str(good_sensors.index(xsplit[0]))\n",
    "                fw.write(\",\".join(xsplit))\n",
    "        \n",
    "    flines = f2.readlines()\n",
    "    fw2.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if xsplit[0] in good_sensors:\n",
    "                xsplit[0] = str(good_sensors.index(xsplit[0]))\n",
    "                fw2.write(\",\".join(xsplit))\n",
    "\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    f2.close()\n",
    "    fw2.close()\n",
    "\n",
    "def juntar_test_data():\n",
    "    f_new = open('data.csv', 'w')\n",
    "    f1 = open('test_data.csv')\n",
    "    f2 = open('train_data.csv')\n",
    "    \n",
    "    flines = f1.readlines()\n",
    "    \n",
    "    f_new.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            f_new.write(\",\".join(xsplit))\n",
    "                \n",
    "    flines = f2.readlines()\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            f_new.write(\",\".join(xsplit))\n",
    "\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f_new.close()\n",
    "\n",
    "def limpiar_s():\n",
    "    f1_new = open('train_data.csv','w')\n",
    "    f2_new = open('test_data.csv','w')\n",
    "    f1 = open('changed_train_sensor_data_cool.csv')\n",
    "    f2 = open('changed_test_sensor_data_cool.csv')\n",
    "\n",
    "    flines = f1.readlines()\n",
    "    \n",
    "    f1_new.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if(xsplit[4] == 'S1 obj'):\n",
    "                xsplit[4] = '1'\n",
    "            elif('S2 nomatch' in xsplit[4]):\n",
    "                xsplit[4] = '2'\n",
    "            elif(xsplit[4]== 'S2 match'):\n",
    "                xsplit[4] = '3'\n",
    "                \n",
    "            if(xsplit[0] == 'S1 obj'):\n",
    "                xsplit[0] = '1'\n",
    "            elif('S2 nomatch' in xsplit[4]):\n",
    "                xsplit[0] = '2'\n",
    "            elif(xsplit[0]== 'S2 match'):\n",
    "                xsplit[0] = '3'\n",
    "            if(xsplit[5] < '64'):\n",
    "                f2_new.write(\",\".join(xsplit))\n",
    "\n",
    "                \n",
    "    flines = f2.readlines()\n",
    "    f2_new.write(flines[0])\n",
    "    for i in tqdm(range(1, len(flines))):\n",
    "        if len(flines[i]) > 3:\n",
    "            xsplit = flines[i].split(',')\n",
    "            if(xsplit[4] == 'S1 obj'):\n",
    "                xsplit[4] = '1'\n",
    "            elif('S2 nomatch' in xsplit[4]):\n",
    "                xsplit[4] = '2'\n",
    "            elif(xsplit[4]== 'S2 match'):\n",
    "                xsplit[4] = '3'\n",
    "            f1_new.write(\",\".join(xsplit))\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f1_new.close()\n",
    "    f2_new.close()\n",
    "                \n",
    "\n",
    "print('Empezando')\n",
    "print('filtrando columnas')\n",
    "#filter_columns()\n",
    "print('cambiando los nombres de los sensores')\n",
    "#change_sensors()\n",
    "print('filtrando sensores')\n",
    "#filter_sensor()\n",
    "print('limpiando s')\n",
    "#limpiar_s()\n",
    "print('juntando test and train')\n",
    "#juntar_test_data()\n",
    "print('terminado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enseguida procederemos a visualizar los datos para aplicar los filtros necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_position</th>\n",
       "      <th>sample_num</th>\n",
       "      <th>sensor_value</th>\n",
       "      <th>subject_identifier</th>\n",
       "      <th>matching_condition</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.276</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.717</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.670</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9.623</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9.623</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.647</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5.229</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.322</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.096</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_position  sample_num  sensor_value subject_identifier  \\\n",
       "0                1           0         0.834                  a   \n",
       "1                1           1         3.276                  a   \n",
       "2                1           2         5.717                  a   \n",
       "3                1           3         7.670                  a   \n",
       "4                1           4         9.623                  a   \n",
       "5                1           5         9.623                  a   \n",
       "6                1           6         8.647                  a   \n",
       "7                1           7         5.229                  a   \n",
       "8                1           8         1.322                  a   \n",
       "9                1           9        -2.096                  a   \n",
       "\n",
       "   matching_condition channel  \n",
       "0                   1       1  \n",
       "1                   1       1  \n",
       "2                   1       1  \n",
       "3                   1       1  \n",
       "4                   1       1  \n",
       "5                   1       1  \n",
       "6                   1       1  \n",
       "7                   1       1  \n",
       "8                   1       1  \n",
       "9                   1       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\",encoding='latin-1')\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enseguida lo que haremos sera clasificar los alcoholicos 'a' como 1 y grupo de control como 0 (campo a clasificar)\n",
    "además que solo usaremos los campos \"sensor_position\",\"sample_num\",\"sensor_value\",\"matching_condition\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"subject_identifier\"]=data[\"subject_identifier\"].map({'a':1,'c':0})\n",
    "temporal = [[data[\"sensor_position\"]],[data[\"sample_num\"]],[data[\"sensor_value\"]],[data[\"matching_condition\"]]]\n",
    "train = np.array(temporal)\n",
    "y = np.array([data['subject_identifier']])\n",
    "\n",
    "train = train.reshape(6621824,4)\n",
    "y = y.reshape(6621824,1)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train , y, test_size=0.002, random_state=42)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_test , y_test, test_size=0.25, random_state=42)\n",
    "# 2 ceros jala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "Teniendo los datasets de train y de prueba procederemos a entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing\n",
    "Ya entrenado el modelo procederemos a medir diferentes mediciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de SGDC\n",
      "\n",
      "                     Predicted no alcoholic  Predicted alcoholic\n",
      "Actual no alcoholic                     148                 1476\n",
      "Actual alcoholic                        306                 1381\n",
      "score 0.46179401993355484\n",
      "recall 0.8186129223473622\n",
      "precision 0.4833741687084354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Modelo de SGDC\")\n",
    "print(\"\")\n",
    "m_confusion_test_svm = metrics.confusion_matrix(y_test, clf.predict(X_test))\n",
    "print(pd.DataFrame(data = m_confusion_test_svm, columns = ['Predicted no alcoholic', 'Predicted alcoholic'],\n",
    "            index = ['Actual no alcoholic', 'Actual alcoholic']))\n",
    "\n",
    "print(\"score\",clf.score(X_test, y_test))\n",
    "print(\"recall\",metrics.recall_score(y_test, clf.predict(X_test)))\n",
    "print(\"precision\",metrics.precision_score(y_test, clf.predict(X_test)))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
